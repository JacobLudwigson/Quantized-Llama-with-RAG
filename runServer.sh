llama.cpp/build/bin/llama-server -m Llama-3.2-3B-Instruct-IQ3_M.gguf -c 1024;
